# -*- coding: utf-8 -*-
"""HW2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1anmyUdnaiTRq1wcz4Vczo6gdn2QXU_H9
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib widget
# %matplotlib inline
from sys import float_info
from math import ceil, floor
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy.optimize import minimize
from scipy.stats import multivariate_normal as mvn
from sklearn.preprocessing import PolynomialFeatures
np.set_printoptions(suppress=True)
np.random.seed(7)

def generate_data(N, pdf):
  n = pdf['mo'].shape[1]
  u = np.random.rand(N)
  thresholds = np.cumsum(np.append(pdf['gmm_w'].dot(pdf['prior'][0]), pdf['prior'][1]))
  thresholds = np.insert(thresholds, 0, 0)
  labels = u >= pdf['prior'][0]
  X = np.zeros((N, n))
  guass = len(pdf['mo'])
  for i in range(0, guass):
    indice = np.argwhere((thresholds[i-1] <= u) & (u <= thresholds[i]))[:, 0]
    X[indice, :] = mvn.rvs(pdf['mo'][i-1], pdf['Co'][i-1], len(indice))
  return X, labels

pdf = {
    'prior': np.array([0.6, 0.4]),
    'gmm_w': np.array([0.5, 0.5, 0.5, 0.5]),
    'mo': np.array([[-1, -1], [1, 1], [-1, 1], [1, -1]]),
    'Co': np.array([[[1,0], [0, 1]],
                    [[1,0], [0, 1]],
                    [[1,0], [0, 1]],
                    [[1,0], [0, 1]]])
}

Sample_training = [20, 200, 2000]
#fig, ax = plt.subplots(2, 2, figsize=(10, 10))
X_train = []
labels_train = []
N_labels_train = []
fig = plt.figure(figsize=(14,14))

#Sample and their labels for training for 20 samples

X_20, labels_20 = generate_data(20, pdf)
X_train.append(X_20)
labels_train.append(labels_20)
N_labels_train.append(np.array((sum(labels_20 == 0), sum(labels_20 == 1))))
ax = fig.add_subplot(221)
ax.set_title(r" Training $D^{20}$")
ax.scatter(X_20[labels_20 == 0,0], X_20[labels_20 == 0, 1],s=18, alpha=1, marker = 'o', label="Class 0")
ax.scatter(X_20[labels_20 == 1,0], X_20[labels_20 == 1, 1],s=18, alpha=1, marker = '*', label="Class 1")
ax.set_xlabel(r"$x_1$")
ax.set_ylabel(r"$x_2$")

#Sample and their labels for training for 200 samples

X_200, labels_200 = generate_data(200, pdf)
X_train.append(X_200)
labels_train.append(labels_200)
N_labels_train.append(np.array((sum(labels_200 == 0), sum(labels_200 == 1))))
ax1 = fig.add_subplot(222)
ax1.set_title(r" Training $D^{200}$")
ax1.scatter(X_200[labels_200 == 0,0], X_200[labels_200 == 0, 1],s=18, alpha=1, marker = 'o', label="Class 0")
ax1.scatter(X_200[labels_200 == 1,0], X_200[labels_200 == 1, 1],s=18, alpha=1, marker = '*', label="Class 1")
ax1.set_xlabel(r"$x_1$")
ax1.set_ylabel(r"$x_2$")


#Sample and their labels for training for 2000 samples

X_2000, labels_2000 = generate_data(2000, pdf)
X_train.append(X_2000)
labels_train.append(labels_2000)
N_labels_train.append(np.array((sum(labels_2000 == 0), sum(labels_2000 == 1))))
ax2 = fig.add_subplot(223)
ax2.set_title(r" Training $D^{2000}$")
ax2.scatter(X_2000[labels_2000 == 0,0], X_2000[labels_2000 == 0, 1],s=18, alpha=1, marker = 'o', label="Class 0")
ax2.scatter(X_2000[labels_2000 == 1,0], X_2000[labels_2000 == 1, 1],s=18, alpha=1, marker = '*', label="Class 1")
ax2.set_xlabel(r"$x_1$")
ax2.set_ylabel(r"$x_2$")
ax.legend()
ax1.legend()
ax2.legend()

#Sample and their labels for Validation for 10000 samples

Sample_validation = 10000
X_valid, labels_valid = generate_data(Sample_validation, pdf)
N1_valid = np.array((sum(labels_valid == 0), sum(labels_valid == 1)))
ax3 = fig.add_subplot(224)
ax3.set_title(r"Validation %D^{10000}$")
ax3.scatter(X_valid[labels_valid==0, 0], X_valid[labels_valid==0, 1],s=18, alpha=1, marker = 'o', label="Class 0")
ax3.scatter(X_valid[labels_valid==1, 0], X_valid[labels_valid==1, 1],s=18, alpha=1, marker = '*', label="Class 1")
ax3.set_xlabel(r"$x_1$")
ax3.set_ylabel(r"$x_2$")
ax3.legend()

x1_valid_lim = (floor(np.min(X_valid[:,0])), ceil(np.max(X_valid[:,0])))
x2_valid_lim = (floor(np.min(X_valid[:,1])), ceil(np.max(X_valid[:,1])))

plt.setp(ax, xlim=x1_valid_lim, ylim=x2_valid_lim)
plt.tight_layout()
plt.show()

def erm_discriminant(X, pdf):
  class_lld_0 = (pdf['gmm_w'][0]*mvn.pdf(X,pdf['mo'][0], pdf['Co'][0]) + pdf['gmm_w'][1]*mvn.pdf(X,pdf['mo'][1], pdf['Co'][1]))
  class_lld_1 = (pdf['gmm_w'][2]*mvn.pdf(X,pdf['mo'][2], pdf['Co'][2]) + pdf['gmm_w'][3]*mvn.pdf(X,pdf['mo'][3], pdf['Co'][3]))
  erm_scores = np.log(class_lld_1) - np.log(class_lld_0)
  return erm_scores

def estimate_roc(d_score, labels, N_labels):
  sorted_score = sorted(d_score)
  gammas = ([sorted_score[0] - float_info.epsilon] + sorted_score + sorted_score[-1] + float_info.epsilon)
  decisions = [d_score >= g for g in gammas]
  ind10 = [np.argwhere((d==1) & (labels == 0)) for d in decisions]
  p10 = [len(inds) / N_labels[0] for inds in ind10]
  ind11 = [np.argwhere((d==1) & (labels == 1)) for d in decisions]
  p11 = [len(inds) / N_labels[1] for inds in ind11]
  roc = {
      'p10': np.array(p10),
      'p11': np.array(p11)
  }
  return roc, gammas

def get_binary_classification_metrics(predictions, labels, N_labels):
  class_metrics = {}
  class_metrics['TN'] = np.argwhere((predictions == 0) & (labels == 0))
  class_metrics['TNR'] = len(class_metrics['TN']) / N_labels[0]
  class_metrics['FP'] = np.argwhere((predictions == 1) & (labels == 0))
  class_metrics['FPR'] = len(class_metrics['FP']) / N_labels[0]
  class_metrics['FN'] = np.argwhere((predictions == 0) & (labels == 1))
  class_metrics['FNR'] = len(class_metrics['FN']) / N_labels[1]
  class_metrics['TP'] = np.argwhere((predictions == 1) & (labels == 1))
  class_metrics['TPR'] = len(class_metrics['TP']) / N_labels[1]

  return class_metrics

disc_erm_scores = erm_discriminant(X_valid, pdf)
roc_erm, gammas_empirical = estimate_roc(disc_erm_scores, labels_valid, N1_valid)
fig_roc = plt.figure(figsize=(10,10))
ax_roc = fig_roc.add_subplot(111)
ax_roc.plot(roc_erm['p10'], roc_erm['p11'])

ax_roc.set_xlabel(r"Probability of False Alarm $p(D=1\,|\,L=0)$")

ax_roc.set_ylabel(r"Probability of True Positive $p(D=1\,|\,L=1)$")

prob_error_empirical = np.array((roc_erm['p10'], 1 - roc_erm['p11'])).T.dot(N1_valid / Sample_validation)

min_prob_error_empirical = np.min(prob_error_empirical)
min_ind_empirical = np.argmin(prob_error_empirical)

gamma_map = pdf['prior'][0] / pdf['prior'][1]
decisions_map = disc_erm_scores >= np.log(gamma_map)

class_metrics_map = get_binary_classification_metrics(decisions_map, labels_valid, N1_valid)
min_prob_error_map = np.array((class_metrics_map['FPR'] * pdf['prior'][0] + class_metrics_map['FNR'] * pdf['prior'][1]))

ax_roc.plot(roc_erm['p10'][min_ind_empirical], roc_erm['p11'][min_ind_empirical], 'o', label='Empirical Minimum Probability: {:.3f}'.format(min_prob_error_empirical)),markersize=14)
ax_roc.plot(class_metrics_map['FPR'], class_metrics_map['TPR'], '+', label='Theoretical Minimum Probability: {:.3f}'.format(min_prob_error_map), markersize=14)
ax_roc.legend()
plt.title("Empirical ERM Classifier ROC Curve")
plt.tight_layout()
plt.show()

print("Minimum Emperical probability: ",  "{:.4f}".format(min_prob_error_empirical))
print("Empirical Gamma: ", "{:.3f}".format(np.exp(gammas_empirical[min_ind_empirical])))

print("Minimum Theoretical probability: ",  "{:.4f}".format(min_prob_error_map))
print("Theoretical Gamma: ", "{:.3f}".format(gamma_map))

def prediction_score(X_bound, Y_bound, pdf, phi=None, num_cord=200):
  xx, yy = np.meshgrid(np.linspace(X_bound[0], X_bound[1], num_cord), np.linspace(Y_bound[0], Y_bound[1], num_cord))
  grid = np.c_[xx.ravel(), yy.ravel()]
  if phi:
    grid = phi.transform(grid)
  Z = erm_discriminant(grid, pdf).reshape(xx.shape)
  return xx, yy, Z

def plot_erm(ax, X, pdf, phi=None):
  X_bound = (floor(np.min(X[:,0])), ceil(np.max(X[:, 0])))
  Y_bound = (floor(np.min(X[:,1])), ceil(np.max(X[:, 1])))

  xx, yy, Z = prediction_score(X_bound, Y_bound, pdf, phi=None)

  equal_levels = np.array((0.3, 0.6, 0.9))
  min_Z = np.min(Z) * equal_levels[::-1]
  max_Z = np.max(Z) * equal_levels

  contour_levels = min_Z.tolist() + [0] + max_Z.tolist()
  cs = ax.contour(xx, yy, Z, contour_levels, colors='k')
  ax_disc.clabel(cs, fontsize=14, inline=1)

plot00 = X_valid[class_metrics_map['TN'], 0]
plot01 = X_valid[class_metrics_map['TN'], 1]
plot10 = X_valid[class_metrics_map['FP'], 0]
plot11 = X_valid[class_metrics_map['FP'], 1]
plot20 = X_valid[class_metrics_map['FN'], 0]
plot21 = X_valid[class_metrics_map['FN'], 1]
plot30 = X_valid[class_metrics_map['TP'], 0]
plot31 = X_valid[class_metrics_map['TP'], 1]

fig_disc_grid = plt.figure(figsize=(8, 8));
ax_disc = fig_disc_grid.add_subplot(111);
ax_disc.set_title(r"Validation $D^{10000}$");
ax_disc.plot(plot00, plot01, 'o', label="Correct Class 0");
ax_disc.plot(plot10, plot11, '+', label="InCorrect Class 0");
ax_disc.plot(plot20, plot21, 'x', label="InCorrect Class 1");
ax_disc.plot(plot30, plot31, 'X', label="Correct Class 1");
ax_disc.set_xlabel(r"$x_1$")
ax_disc.set_ylabel(r"$x_2$")
plot_erm(ax_disc, X_valid, pdf)
ax_disc.set_aspect('equal')
ax_disc.legend()
plt.tight_layout()
plt.show()

Epi = 1e-7

def logistic_prediction(X, w):
  logits = X.dot(w)
  y = 1 + np.exp(-logits)
  value = 1.0/y
  return value

def negative_log_likelihood(labels, predictions):
  predict1 = np.clip(predictions, Epi, 1-Epi)
  log_p0 = (1-labels)*np.log(1 - predict1 + Epi)
  log_p1 = labels * np.log(predict1 + Epi)
  return -np.mean(log_p0 + log_p1, axis=0)

def Compute_param_logistic(X, labels):
  theta0 = np.random.randn(X.shape[1])
  cost_fun = lambda w: negative_log_likelihood(labels, logistic_prediction(X, w))
  res = minimize(cost_fun, theta0, tol=1e-6)
  return res.x

def prediction_score_grid(X_bound, Y_bound, pdf, phi=None, num_cord=200):
  xx, yy = np.meshgrid(np.linspace(X_bound[0], X_bound[1], num_cord), np.linspace(Y_bound[0], Y_bound[1], num_cord))
  grid = np.c_[xx.ravel(), yy.ravel()]
  if phi:
    grid = phi.transform(grid)
  Z = logistic_prediction(grid, pdf).reshape(xx.shape)
  return xx, yy, Z

def logistic_classifier(ax, X, w, labels, N_labels, phi=None):
  predictions = logistic_prediction(phi.fit_transform(X), w)
  decisions = np.array(predictions >= 0.5)
  logistic_metrics = get_binary_classification_metrics(decisions, labels, N_labels)
  probability_error = np.array((logistic_metrics['FPR'], logistic_metrics['FNR'])).T.dot(N_labels / labels.shape[0])
  ax.plot(X[logistic_metrics['TN'], 0], X[logistic_metrics['TN'], 1], 'og', label="Correct Class 0");
  ax.plot(X[logistic_metrics['FP'], 0], X[logistic_metrics['FP'], 1], 'or', label="Incorrect Class 0");
  ax.plot(X[logistic_metrics['FN'], 0], X[logistic_metrics['FN'], 1], '+r', label="Incorrect Class 1");
  ax.plot(X[logistic_metrics['TP'], 0], X[logistic_metrics['TP'], 1], '+g', label="Correct Class 1");
  xx, yy, Z = prediction_score_grid(x1_valid_lim, x2_valid_lim, w, phi)
  cs = ax.contour(xx, yy, Z, levels=1, colors='k')
  ax.set_xlabel(r"$x_1$")
  ax.set_ylabel(r"$x_2$")
  return probability_error

fig_linear = plt.figure(figsize=(15, 15))
ax_linear_20 = fig_linear.add_subplot(321)
ax_linear_200 = fig_linear.add_subplot(323)
ax_linear_2000 = fig_linear.add_subplot(325)
phi = PolynomialFeatures(degree=1)

# 20 samples
w_mle_20 = Compute_param_logistic(phi.fit_transform(X_train[0]), labels_train[0])
probability_error = logistic_classifier(ax_linear_20, X_train[0], w_mle_20, labels_train[0], N_labels_train[0], phi)
ax_linear_20.set_title("ji")
ax_linear_20.set_xticks([])

# 200 samples
w_mle_200 = Compute_param_logistic(phi.fit_transform(X_train[1]), labels_train[1])
probability_error = logistic_classifier(ax_linear_200, X_train[1], w_mle_200, labels_train[1], N_labels_train[1], phi)
ax_linear_200.set_title("ji")
ax_linear_200.set_xticks([])

# 2000 samples
w_mle_2000 = Compute_param_logistic(phi.fit_transform(X_train[2]), labels_train[2])
probability_error = logistic_classifier(ax_linear_2000, X_train[2], w_mle_2000, labels_train[2], N_labels_train[2], phi)
ax_linear_2000.set_title("ji")
ax_linear_2000.set_xticks([])

ax_linear_422 = fig_linear.add_subplot(322)
ax_linear_424 = fig_linear.add_subplot(324)
ax_linear_426 = fig_linear.add_subplot(326)

probability_error = logistic_classifier(ax_linear_422, X_valid, w_mle_20, labels_valid, N1_valid, phi)
ax_linear_422.set_title("ji")
ax_linear_422.set_xticks([])

probability_error = logistic_classifier(ax_linear_424, X_valid, w_mle_200, labels_valid, N1_valid, phi)
ax_linear_424.set_title("ji")
ax_linear_424.set_xticks([])

probability_error = logistic_classifier(ax_linear_426, X_valid, w_mle_2000, labels_valid, N1_valid, phi)
ax_linear_426.set_title("ji")
ax_linear_426.set_xticks([])

handles, labels = ax_linear_20.get_legend_handles_labels()
fig_linear.legend(handles, labels, loc='lower center')
plt.setp(ax_linear_20, xlim=x1_valid_lim, ylim=x2_valid_lim)
plt.show()

fig_linear = plt.figure(figsize=(15, 15))
ax_linear_20 = fig_linear.add_subplot(321)
ax_linear_200 = fig_linear.add_subplot(323)
ax_linear_2000 = fig_linear.add_subplot(325)
phi = PolynomialFeatures(degree=2)

# 20 samples
w_mle_20 = Compute_param_logistic(phi.fit_transform(X_train[0]), labels_train[0])
probability_error = logistic_classifier(ax_linear_20, X_train[0], w_mle_20, labels_train[0], N_labels_train[0], phi)
ax_linear_20.set_title("ji")
ax_linear_20.set_xticks([])

# 200 samples
w_mle_200 = Compute_param_logistic(phi.fit_transform(X_train[1]), labels_train[1])
probability_error = logistic_classifier(ax_linear_200, X_train[1], w_mle_200, labels_train[1], N_labels_train[1], phi)
ax_linear_200.set_title("ji")
ax_linear_200.set_xticks([])

# 2000 samples
w_mle_2000 = Compute_param_logistic(phi.fit_transform(X_train[2]), labels_train[2])
probability_error = logistic_classifier(ax_linear_2000, X_train[2], w_mle_2000, labels_train[2], N_labels_train[2], phi)
ax_linear_2000.set_title("ji")
ax_linear_2000.set_xticks([])

ax_linear_422 = fig_linear.add_subplot(322)
ax_linear_424 = fig_linear.add_subplot(324)
ax_linear_426 = fig_linear.add_subplot(326)

probability_error = logistic_classifier(ax_linear_422, X_valid, w_mle_20, labels_valid, N1_valid, phi)
ax_linear_422.set_title("ji")
ax_linear_422.set_xticks([])

probability_error = logistic_classifier(ax_linear_424, X_valid, w_mle_200, labels_valid, N1_valid, phi)
ax_linear_424.set_title("ji")
ax_linear_424.set_xticks([])

probability_error = logistic_classifier(ax_linear_426, X_valid, w_mle_2000, labels_valid, N1_valid, phi)
ax_linear_426.set_title("ji")
ax_linear_426.set_xticks([])

handles, labels = ax_linear_20.get_legend_handles_labels()
fig_linear.legend(handles, labels, loc='lower center')
plt.setp(ax_linear_20, xlim=x1_valid_lim, ylim=x2_valid_lim)

